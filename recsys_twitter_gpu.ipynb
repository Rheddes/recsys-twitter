{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recsys-twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rheddes/recsys-twitter/blob/master/recsys_twitter_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZn8mKIfxjK",
        "colab_type": "text"
      },
      "source": [
        "# Necessary imports & definitions\n",
        "\n",
        "Copy files from drive to local disk, not necessary it is also possible to work directly from drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEaruqpdxx8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1D3hQ7N2MNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp ./drive/My\\ Drive/RecSys/train_updated.tsv train_updated.tsv\n",
        "# !cp ./drive/My\\ Drive/RecSys/sample.tsv sample.tsv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqMvNlDcTy-u",
        "colab_type": "text"
      },
      "source": [
        "Set train file variable to correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHeXqCv8Tmwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = './drive/My Drive/RecSys/sample.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKpRWGTETnLR",
        "colab_type": "text"
      },
      "source": [
        "## Install transformers (for BERT models)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MSNEuZ9vf-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWHBKWxKTsU9",
        "colab_type": "text"
      },
      "source": [
        "## Nvidia stats & info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET_38Y0Sz0Fv",
        "colab_type": "code",
        "outputId": "eba830be-6feb-47ba-e7ae-2bf179609177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# !nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 26 18:37:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    59W / 149W |  10408MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvX-aYUwTv8C",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVMsiUBbfw14",
        "colab_type": "code",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import gc\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from helpers.dataset import MyIterableDataset\n",
        "from helpers.bert_functions import make_bert_model, get_bert_classification_vectors, create_attention_mask_from\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import islice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU4-Tk9oT-sl",
        "colab_type": "text"
      },
      "source": [
        "## Tell pytorch to use cuda if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15tcccN2yX1l",
        "colab_type": "code",
        "outputId": "036fbaf9-862b-4a3b-8163-eaa650726050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "use_cuda = True\n",
        "\n",
        "print(\"Cuda is available: \", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"using device: \", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda is available:  True\n",
            "using device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgEcpwUjUCKn",
        "colab_type": "text"
      },
      "source": [
        "## Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m0j0hpGs4kr",
        "colab_type": "code",
        "outputId": "f8f84d4d-3bb4-4873-c430-1835154570c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = make_bert_model()\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI1kmB_af9WF",
        "colab_type": "text"
      },
      "source": [
        "# Read the desired dataset\n",
        "\n",
        "This piece of code can be used to create dataset and loader objects which allow stream reading the dataset, as to not occupy to much memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7vmmxXpyQAx",
        "colab_type": "text"
      },
      "source": [
        "## Create dataset\n",
        "\n",
        "Custom dataset type to iterate throught the training file, also performs some preprocessing (see `helpers/dataset.py` for details)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAAWvn6uadyv",
        "colab_type": "code",
        "outputId": "ed857f5e-c9fb-4579-a3f3-4cc264386f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iterable_dataset = MyIterableDataset(train_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPMFdbayyBND",
        "colab_type": "text"
      },
      "source": [
        "## Create loader\n",
        "\n",
        "The loader reads batches from the dataset and outputs it as an iterable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBgIRMrdyF8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DataLoader(iterable_dataset, batch_size=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P81_gDcf19wq",
        "colab_type": "text"
      },
      "source": [
        "# Model 1: (distil)BERT\n",
        "\n",
        "This model transform the list of ordered BERT id's in to a feature vector on which we can use regular classfiers (i.e. logistics classifiers, or kNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jANwvEH5VKqL",
        "colab_type": "text"
      },
      "source": [
        "### Clean GPU memory\n",
        "\n",
        "After running the model some things are left in the memory of the GPU this attempts to clean up as much as possible. Certainly not perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2QqVpklLO5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean GPU cache\n",
        "if use_cuda:\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-CSjbv2kxtzF",
        "colab_type": "text"
      },
      "source": [
        "## Run model on DataLoader (automatically batched)\n",
        "\n",
        "In order to work on larger datasets we can work in batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qVOJyNXhxtzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = None\n",
        "labels = None\n",
        "index = 0\n",
        "number_of_iterations\n",
        "with torch.no_grad():\n",
        "  if use_cuda:\n",
        "    model.cuda()\n",
        "  for batch in islice(loader, number_of_iterations):\n",
        "    batch_ids = batch[0]\n",
        "    batch_labels = batch[4]\n",
        "    mask = create_attention_mask_from(batch_ids)\n",
        "\n",
        "    if use_cuda:\n",
        "      batch_ids, mask = batch_ids.to(device), mask.to(device)\n",
        "\n",
        "    last_hidden_states = model(batch_ids, attention_mask=mask)\n",
        "    last_features = get_bert_classification_vectors(last_hidden_states, use_cuda)\n",
        "\n",
        "    features = np.concatenate((features, last_features)) if features is not None else last_features\n",
        "    labels = np.concatenate((labels, batch_labels)) if labels is not None else batch_labels\n",
        "    \n",
        "    print(index)\n",
        "    index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8jp9iiv1xtzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "u6pjgUjVxtzL",
        "colab_type": "text"
      },
      "source": [
        "### Get output from model\n",
        "\n",
        "See if lengths of feature set and labels set match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2jt9kuwwxtzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(features))\n",
        "print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "B_IVd-WIxtzN",
        "colab_type": "text"
      },
      "source": [
        "# Model 2: Logistics classifier\n",
        "We got our output from the BERT model we can now train our logistics classifier to actually classify tweet engagements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW1DWJUg3mMe",
        "colab_type": "text"
      },
      "source": [
        "First we split our training set up into train & test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_98YcFo63qIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neWbHo4c391S",
        "colab_type": "text"
      },
      "source": [
        "Next train our Logistics Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btnSZmZg4AFY",
        "colab_type": "code",
        "outputId": "a7728eb1-a784-468e-a665-c40f1468f4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8XutF_H4jdx",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating classifier\n",
        "\n",
        "Now that we have our trained classifier let's see how it performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpRcU1JB4nyW",
        "colab_type": "code",
        "outputId": "2130a00c-b849-4ebe-a379-e5b4257223aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZusXK0D4prC",
        "colab_type": "text"
      },
      "source": [
        "Let's compare that to a dummy classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVtkT5Kk4sBd",
        "colab_type": "code",
        "outputId": "b165992b-d1a5-40f3-cb9b-0cbc26f2bdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.600 (+/- 0.75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTUx_wbt4wpj",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "So we currently perform ~10% better than a dummy classifier, awesome."
      ]
    }
  ]
}