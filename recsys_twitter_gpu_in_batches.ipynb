{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of recsys-twitter-gpu-in-batches.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1bb6c04ff214bfc8702aaa068d352ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f0e04c188ae40968060e89da1a18a72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbc3ee0e18e94220b3665a7457a87093",
              "IPY_MODEL_3a8d1d7827694aedb40fd3cdce1a947e"
            ]
          }
        },
        "0f0e04c188ae40968060e89da1a18a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbc3ee0e18e94220b3665a7457a87093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e52ed7eef2454c25a4b86f911441d9f1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b241d5c62f4147dfa436836768110356"
          }
        },
        "3a8d1d7827694aedb40fd3cdce1a947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5164930eb23544c0be74ac5987feefef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466/466 [03:15&lt;00:00, 2.38B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_735f09968a734b3fb910531ef1a3c71e"
          }
        },
        "e52ed7eef2454c25a4b86f911441d9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b241d5c62f4147dfa436836768110356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5164930eb23544c0be74ac5987feefef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "735f09968a734b3fb910531ef1a3c71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40061f09c2174bdbbb14953dde62eed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3526f4ab1b04609af57a795fe4a55ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8103bb4b1a5142b7986648cfa3c0c10f",
              "IPY_MODEL_414a43d05a1048399628735dac71376f"
            ]
          }
        },
        "f3526f4ab1b04609af57a795fe4a55ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8103bb4b1a5142b7986648cfa3c0c10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55f41b512a194d99ace14044aa7d24fb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 541808922,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 541808922,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b79404beea894182b406a90dcc028b2b"
          }
        },
        "414a43d05a1048399628735dac71376f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b0a6c193c8a47ae80fe53332b5732a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 542M/542M [01:16&lt;00:00, 7.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_129bc2654c7543718fc83800f74c4165"
          }
        },
        "55f41b512a194d99ace14044aa7d24fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b79404beea894182b406a90dcc028b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b0a6c193c8a47ae80fe53332b5732a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "129bc2654c7543718fc83800f74c4165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rheddes/recsys-twitter/blob/feature%2Fbert-extraction-in-batches/recsys_twitter_gpu_in_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nO8SbVv6EwfU",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rheddes/recsys-twitter/blob/feature/bert-extraction-in-batcehs/recsys_twitter_gpu_in_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QEpKaD9nEwfW",
        "colab_type": "text"
      },
      "source": [
        "# Necessary imports & definitions\n",
        "\n",
        "Copy files from drive to local disk, not necessary it is also possible to work directly from drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nR4TTROyEwfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kuKcRbikEwfg",
        "colab_type": "text"
      },
      "source": [
        "## Get validation set\n",
        "\n",
        "Get the validation/prediction set from the challenge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8-L_fix5Ewfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O val.tsv \"https://elasticbeanstalk-us-west-2-800068098556.s3.amazonaws.com/challenge-website/public_data/val.tsv?AWSAccessKeyId=AKIA3UR6GLH6F73MJVWF&Signature=uURRfbcpN3%2BW7tWrUaL6Av8ZX5c%3D&Expires=1588061161\"\n",
        "!cp val.tsv ./drive/My\\ Drive/RecSys/val.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q2RZ47iYEwfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp ./drive/My\\ Drive/RecSys/train_updated.tsv train_updated.tsv\n",
        "# !cp ./drive/My\\ Drive/RecSys/sample.tsv sample.tsv \n",
        "# !cp bert_classification_features.csv  ./drive/My\\ Drive/RecSys/bert_22500.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KwWvo99UEwfs",
        "colab_type": "text"
      },
      "source": [
        "## Set correct batch index\n",
        "\n",
        "In order to circumvent runtime timeouts, we process the dataset in batches.\n",
        "The validation set has been split up in to 4 different files:\n",
        "\n",
        "```\n",
        "./drive/My Drive/RecSys/val{1..4}.tsv\n",
        "```\n",
        "\n",
        "So we need to run the notebook essentially 6 times, each time changing the `TRANSFORM_ITERATION` constant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ehEB0-2UEwfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRANSFORM_ITERATION=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5S6td6DcEwf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_file = './drive/My Drive/RecSys/val.{}.tsv'.format(TRANSFORM_ITERATION)\n",
        "# For testing:\n",
        "# pred_file = './drive/My Drive/RecSys/temp/val_test_subset.{}.tsv'.format(TRANSFORM_ITERATION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jZv8_C5_Ewf6",
        "colab_type": "text"
      },
      "source": [
        "## Install transformers (for BERT models)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7tLmxQ4DEwf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "khOyIJUxEwgE",
        "colab_type": "text"
      },
      "source": [
        "## Install helpers from GitHub\n",
        "\n",
        "To simplify this notebook several helper functions have been abstracted to separate python files in the git repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Fv0ZWAwUEwgF",
        "colab_type": "code",
        "outputId": "ea608439-20a2-4cc8-99d2-a07255c6c67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!rm -rf recsys-twitter helpers\n",
        "!git clone --branch feature/bert-extraction-in-batches https://github.com/Rheddes/recsys-twitter.git\n",
        "!cp -r recsys-twitter/helpers helpers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'recsys-twitter'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 86 (delta 45), reused 46 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "uhhQgoh4EwgI",
        "colab_type": "text"
      },
      "source": [
        "## Nvidia stats & info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-tQK8IbCEwgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sjpRhcbiEwgP",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YHPsG3B0EwgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch\n",
        "from helpers.dataset import PredictionDataset\n",
        "from helpers.bert_functions import make_bert_model, get_bert_classification_vectors, create_attention_mask_from\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7-htB02JEwgT",
        "colab_type": "text"
      },
      "source": [
        "## Tell pytorch to use cuda if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8zPsdcxsEwgU",
        "colab_type": "code",
        "outputId": "460cb4a4-4a84-4ea9-cf76-917035012aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "use_cuda = True\n",
        "\n",
        "print(\"Cuda is available: \", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"using device: \", device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda is available:  True\n",
            "using device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Eq3GRF9BEwgb",
        "colab_type": "text"
      },
      "source": [
        "## Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6Qmhspg5Ewgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "d1bb6c04ff214bfc8702aaa068d352ca",
            "0f0e04c188ae40968060e89da1a18a72",
            "dbc3ee0e18e94220b3665a7457a87093",
            "3a8d1d7827694aedb40fd3cdce1a947e",
            "e52ed7eef2454c25a4b86f911441d9f1",
            "b241d5c62f4147dfa436836768110356",
            "5164930eb23544c0be74ac5987feefef",
            "735f09968a734b3fb910531ef1a3c71e",
            "40061f09c2174bdbbb14953dde62eed5",
            "f3526f4ab1b04609af57a795fe4a55ba",
            "8103bb4b1a5142b7986648cfa3c0c10f",
            "414a43d05a1048399628735dac71376f",
            "55f41b512a194d99ace14044aa7d24fb",
            "b79404beea894182b406a90dcc028b2b",
            "1b0a6c193c8a47ae80fe53332b5732a8",
            "129bc2654c7543718fc83800f74c4165"
          ]
        },
        "outputId": "70f5324c-a84f-4f4e-caa6-7b0b96c51f5d"
      },
      "source": [
        "model = make_bert_model()\n",
        "print('done')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1bb6c04ff214bfc8702aaa068d352ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40061f09c2174bdbbb14953dde62eed5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541808922.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FFbVQBlIEwgh",
        "colab_type": "text"
      },
      "source": [
        "# Read the desired dataset\n",
        "\n",
        "This piece of code can be used to create dataset and loader objects which allow stream reading the dataset, as to not occupy to much memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3q7FGt_pEwgi",
        "colab_type": "text"
      },
      "source": [
        "## Create dataset\n",
        "\n",
        "Custom dataset type to iterate throught the training file, also performs some preprocessing (see `helpers/dataset.py` for details)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z_gXSS8SEwgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterable_dataset = PredictionDataset(pred_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bCLs-ENaEwgn",
        "colab_type": "text"
      },
      "source": [
        "## Read dataset with pandas\n",
        "\n",
        "As to read out the tweet_id & engaging_user_id as to form a primary key for every record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8SsgSw4BEwgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
        "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
        "                \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\",\n",
        "                \"engaged_with_user_account_creation\", \"enaging_user_id\", \"enaging_user_follower_count\",\n",
        "                \"enaging_user_following_count\",\n",
        "                \"enaging_user_is_verified\", \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
        "selected_features = ['tweet_id', 'enaging_user_id']\n",
        "unused_features = list(set(all_features) - set(selected_features))\n",
        "\n",
        "validation = pd.read_csv(pred_file, header=None, sep=\"\\x01\")\n",
        "validation.columns = all_features\n",
        "\n",
        "for unused_feature in unused_features:\n",
        "  del validation[unused_feature]\n",
        "gc.collect()\n",
        "\n",
        "np_tweet_ids = validation['tweet_id'].to_numpy()\n",
        "np_engaging_ids = validation['enaging_user_id'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wERQPSsnEwgp",
        "colab_type": "text"
      },
      "source": [
        "## Create loader\n",
        "\n",
        "The loader reads batches from the dataset and outputs it as an iterable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i9ecL0TZEwgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DataLoader(iterable_dataset, batch_size=150)\n",
        "# For testing\n",
        "# loader = DataLoader(iterable_dataset, batch_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tMY_Fg6JEwgt",
        "colab_type": "text"
      },
      "source": [
        "# Model 1: (distil)BERT\n",
        "\n",
        "This model transform the list of ordered BERT id's in to a feature vector on which we can use regular classfiers (i.e. logistics classifiers, or kNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QdhTLgBeEwgu",
        "colab_type": "text"
      },
      "source": [
        "### Clean GPU memory\n",
        "\n",
        "After running the model some things are left in the memory of the GPU this attempts to clean up as much as possible. Certainly not perfect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "403XUk9gEwgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean GPU cache\n",
        "if use_cuda:\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oGLJwmfNEwgx",
        "colab_type": "text"
      },
      "source": [
        "## Run model on DataLoader (automatically batched)\n",
        "\n",
        "In order to work on larger datasets we can work in batches.\n",
        "\n",
        "Indices:\n",
        "```\n",
        "TOKENS_INDEX = 0\n",
        "REPLIED_INDEX = 1\n",
        "RETWEETED_INDEX = 2\n",
        "RETWEETED_WITH_COMMENT_INDEX = 3\n",
        "LIKE_INDEX = 4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N23kxIAvSXld",
        "colab_type": "text"
      },
      "source": [
        "**CHANGE TRANSFORMATION ITERATION ON LAST LINE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eJ2zaAjoEwgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b596454f-f8a9-4811-bf6c-415db824345e"
      },
      "source": [
        "features = None\n",
        "labels = None\n",
        "with torch.no_grad():\n",
        "  if use_cuda:\n",
        "    model.cuda()\n",
        "  for batch in tqdm(loader):\n",
        "    batch_ids = batch[0]    # Input text_tokens\n",
        "    mask = create_attention_mask_from(batch_ids)\n",
        "\n",
        "    if use_cuda:\n",
        "      batch_ids, mask = batch_ids.to(device), mask.to(device)\n",
        "\n",
        "    last_hidden_states = model(batch_ids, attention_mask=mask)\n",
        "    last_features = get_bert_classification_vectors(last_hidden_states, use_cuda)\n",
        "\n",
        "    features = np.concatenate((features, last_features)) if features is not None else last_features\n",
        "    # print(\"one iteration done\")\n",
        "\n",
        "export_features = np.c_[np_tweet_ids, np_engaging_ids, features]\n",
        "\n",
        "pickle.dump(export_features, open('bert_classification_val.{}.p'.format(TRANSFORM_ITERATION), 'wb+'))\n",
        "!cp bert_classification_val.1.p  ./drive/My\\ Drive/RecSys/features/bert_classification_val.1.p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13it [01:17,  5.83s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "EARuWUKkEwg0",
        "colab_type": "text"
      },
      "source": [
        "### Done transforming data\n",
        "\n",
        "Done for now, the generated features can be easily loaded in to other models."
      ]
    }
  ]
}