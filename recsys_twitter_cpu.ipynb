{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recsys-twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rheddes/recsys-twitter/blob/master/recsys_twitter_cpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSZn8mKIfxjK",
        "colab_type": "text"
      },
      "source": [
        "# Necessary imports & definitions\n",
        "\n",
        "Copy files from drive to local disk, not necessary it is also possible to work directly from drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpSznekwqG7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8d5ede4c-d71d-4d0c-ddac-06b6140efc3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1D3hQ7N2MNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp ./drive/My\\ Drive/RecSys/train_updated.tsv train_updated.tsv\n",
        "# !cp ./drive/My\\ Drive/RecSys/sample.tsv sample.tsv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqMvNlDcTy-u",
        "colab_type": "text"
      },
      "source": [
        "Set train file variable to correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHeXqCv8Tmwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = './drive/My Drive/RecSys/sample.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKpRWGTETnLR",
        "colab_type": "text"
      },
      "source": [
        "## Install transformers (for BERT models)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MSNEuZ9vf-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvX-aYUwTv8C",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVMsiUBbfw14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "import torch\n",
        "import gc\n",
        "import transformers as ppb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgEcpwUjUCKn",
        "colab_type": "text"
      },
      "source": [
        "## Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m0j0hpGs4kr",
        "colab_type": "code",
        "outputId": "8b45034e-5ca7-47ea-e1ef-577eb5b74995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-multilingual-cased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-multilingual-cased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights, do_lower_case=False)\n",
        "model = model_class.from_pretrained(\n",
        "    pretrained_weights,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = True,\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI1kmB_af9WF",
        "colab_type": "text"
      },
      "source": [
        "# Read the desired dataset\n",
        "\n",
        "This piece of code can be used to read the desired dataset into memory as a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAAWvn6uadyv",
        "colab_type": "code",
        "outputId": "a45e8da0-bcd7-4e8b-b630-aa5e26f101aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
        "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
        "                \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\",\n",
        "                \"engaged_with_user_account_creation\", \"enaging_user_id\", \"enaging_user_follower_count\",\n",
        "                \"enaging_user_following_count\",\n",
        "                \"enaging_user_is_verified\", \"enaging_user_account_creation\", \"engagee_follows_engager\",\n",
        "                \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"]\n",
        "                \n",
        "dataset = pd.read_csv(train_file, delimiter=\"\\x01\", encoding='utf-8', header=None)\n",
        "dataset.columns = all_features\n",
        "print(\"done\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P81_gDcf19wq",
        "colab_type": "text"
      },
      "source": [
        "# Model 1: (distil)BERT\n",
        "\n",
        "This model transform the list of ordered BERT id's in to a feature vector on which we can use regular classfiers (i.e. logistics classifiers, or kNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BNc2WUaJu3X",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Prepare model for distilBERT\n",
        "\n",
        "Make small batch set that easily fits in memory, with only necessary data included. It becomes a DataFrame of two columns: `text_token` which contains Numpy arrays of BERT ID's, and `like_timestamp` which contains `1` if liked and `0` if not liked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbK6YXmLVDPO",
        "colab_type": "text"
      },
      "source": [
        "### Create batch\n",
        "\n",
        "In order to not run out of memory we have to work in small batches of the dataset at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F0UcZFK2MH1",
        "colab_type": "code",
        "outputId": "a2b315e0-f771-4ffc-d705-5dd7ce092c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "batch_1 = dataset[:200]\n",
        "batch_1 = batch_1[['text_tokens','like_timestamp']]\n",
        "\n",
        "batch_1.text_tokens = batch_1.text_tokens.apply(lambda x: np.fromstring(x, dtype=int, sep=\"\\t\"))\n",
        "batch_1.like_timestamp = batch_1.like_timestamp.apply(lambda x: 0 if math.isnan(x) else 1)\n",
        "\n",
        "print(batch_1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                           text_tokens  like_timestamp\n",
            "0    [101, 56898, 137, 33909, 10107, 11490, 10288, ...               0\n",
            "1    [101, 137, 74039, 12436, 12396, 12436, 27746, ...               1\n",
            "2    [101, 13229, 21885, 10681, 10380, 31747, 71309...               1\n",
            "3    [101, 14820, 100, 188, 83279, 10142, 10751, 10...               0\n",
            "4    [101, 56898, 137, 12001, 10731, 20498, 20467, ...               0\n",
            "..                                                 ...             ...\n",
            "195  [101, 56898, 137, 156, 11703, 10162, 11447, 34...               0\n",
            "196  [101, 56898, 137, 58768, 28558, 68748, 131, 12...               0\n",
            "197  [101, 11518, 45632, 10192, 10312, 43330, 10107...               1\n",
            "198  [101, 59533, 12028, 89512, 184, 11703, 10164, ...               0\n",
            "199  [101, 1894, 5900, 2226, 2179, 100775, 3365, 20...               1\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWdXkn1HUvON",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Optional\n",
        "\n",
        "Get some stats about the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdrTUz486BUN",
        "colab_type": "code",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e77ed948-280c-4add-8b5a-00ec0b329ae9"
      },
      "source": [
        "batch_1.like_timestamp.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    121\n",
              "1     79\n",
              "Name: like_timestamp, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7khOV2kiU2FE",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Pad text tokens vector\n",
        "\n",
        "In order for BERT model to work with the dataset we have to pad the input matrix rows to same size. So all `text_tokens` arrays have to be same length. Therefore we first calculate what the maximum vector length is in the `text_tokens` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQBGeuD1-vQS",
        "colab_type": "code",
        "outputId": "0cc13423-396f-412d-fe9b-e0af5dc73aad",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len = 0\n",
        "for i in batch_1.text_tokens.values:\n",
        "  if len(i) > max_len:\n",
        "      max_len = len(i)\n",
        "      \n",
        "print(max_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmZFP8Sw2zNR",
        "colab_type": "text"
      },
      "source": [
        "With the `max_len` we can padd all arrays in `text_tokens` to same length and export it to a 2d numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-yjvAtvSAEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d6e7851d-f3e1-4952-d45b-feb518bfcd41"
      },
      "source": [
        "padded = np.array([np.concatenate([i, np.zeros(max_len-len(i), dtype=int)]) for i in batch_1.text_tokens.values])\n",
        "print(padded)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  101 56898   137 ...     0     0     0]\n",
            " [  101   137 74039 ...     0     0     0]\n",
            " [  101 13229 21885 ...     0     0     0]\n",
            " ...\n",
            " [  101 11518 45632 ...     0     0     0]\n",
            " [  101 59533 12028 ...     0     0     0]\n",
            " [  101  1894  5900 ...     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmgjGYz4U3HK",
        "colab_type": "code",
        "outputId": "61029f2b-94b5-4c3a-b8f3-4a47e6f42433",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjXazL3AslFK",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTLnOerusJFz",
        "colab_type": "code",
        "outputId": "09459777-7d2f-4474-da40-aea70d8ca62f",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTS5E4Ey2FfP",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Run model to get hidden states\n",
        "\n",
        "Running the output yields a 768 length vector for each row in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_GuFQLuYqCV-",
        "colab_type": "text"
      },
      "source": [
        "### Load tensors and Run\n",
        "\n",
        "This creates the tensors from input data (and sends them to GPU if available) and runs the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Avw52DMSqCV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "  last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eiGD0H7bqCWC",
        "colab_type": "text"
      },
      "source": [
        "### Get output from model\n",
        "\n",
        "Next we have to get the classification features from the output of BERT to a proper matrix. For more details on this see: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xf2Ae_EtqCWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "63c3954e-0252-48d2-dfb4-bfbfe757abda"
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "print(features)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.17406203 -0.0433972  -0.18433005 ...  0.5506898   0.18670747\n",
            "  -0.198578  ]\n",
            " [-0.11964368 -0.26719     0.14500006 ...  0.30625767  0.03193825\n",
            "  -0.04966999]\n",
            " [ 0.10105906 -0.01484996  0.16492397 ...  0.29651228  0.28076926\n",
            "   0.03425452]\n",
            " ...\n",
            " [-0.13193937  0.15147121  0.02599217 ...  0.28464457  0.00857005\n",
            "  -0.0662995 ]\n",
            " [ 0.06861539 -0.06619139 -0.10860651 ...  0.31563112  0.14870207\n",
            "  -0.04414   ]\n",
            " [-0.2608274  -0.06339766  0.00664555 ...  0.30480263  0.01772955\n",
            "  -0.18186548]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vOSItoowqCWF",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the feature set, it is good to construct our label set as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WL0Rk9wSqCWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = batch_1.like_timestamp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5fIoQsERqCWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e10a2a3d-9bf7-4d34-8572-c9ea87d9a182"
      },
      "source": [
        "print(len(features))\n",
        "print(len(labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSjanwsUtFaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "24046625-ad4f-4e8e-d668-137d441bf66a"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      0\n",
            "1      1\n",
            "2      1\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "195    0\n",
            "196    0\n",
            "197    1\n",
            "198    0\n",
            "199    1\n",
            "Name: like_timestamp, Length: 200, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWnqdzz8VTbp",
        "colab_type": "text"
      },
      "source": [
        "# Model 2: Logistics classifier\n",
        "\n",
        "We got our output from the BERT model we can now train our logistics classifier to actually classify tweet engagements.\n",
        "\n",
        "First we split our training set up into train & test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6qnZyMKXJrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV9OwRE96xSR",
        "colab_type": "text"
      },
      "source": [
        "Next train our Logistics Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biwWIQyEGZgV",
        "colab_type": "code",
        "outputId": "a9c1d494-caae-4f00-ea40-d5785d3bd058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuLtl3EoWEEe",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating classifier\n",
        "\n",
        "Now that we have our trained classifier let's see how it performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV1k5zrv3HWb",
        "colab_type": "code",
        "outputId": "32782e70-39b2-4fa7-f9d4-4031284ee583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTXLYmr3RYA",
        "colab_type": "text"
      },
      "source": [
        "Let's compare that to a dummy classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCwOMtBv3VZl",
        "colab_type": "code",
        "outputId": "903ebde1-dc9a-46dd-d24f-64b2da5942f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.493 (+/- 0.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4kFuFTQBC4N",
        "colab_type": "code",
        "outputId": "f91003a3-d9dc-4a51-f19a-280290647b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "So we currently perform ~10% better than a dummy classifier, awesome."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg98gW2r3kLw",
        "colab_type": "text"
      },
      "source": [
        "# Other stuff (utilities) - not needed to execute\n",
        "\n",
        "Was needed to prepare data for reading etcetera.\n",
        "Some random stuff that was useful before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW1DWJUg3mMe",
        "colab_type": "text"
      },
      "source": [
        "First we split our training set up into train & test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_98YcFo63qIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neWbHo4c391S",
        "colab_type": "text"
      },
      "source": [
        "Next train our Logistics Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btnSZmZg4AFY",
        "colab_type": "code",
        "outputId": "a7728eb1-a784-468e-a665-c40f1468f4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8XutF_H4jdx",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating classifier\n",
        "\n",
        "Now that we have our trained classifier let's see how it performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpRcU1JB4nyW",
        "colab_type": "code",
        "outputId": "2130a00c-b849-4ebe-a379-e5b4257223aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZusXK0D4prC",
        "colab_type": "text"
      },
      "source": [
        "Let's compare that to a dummy classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVtkT5Kk4sBd",
        "colab_type": "code",
        "outputId": "b165992b-d1a5-40f3-cb9b-0cbc26f2bdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.600 (+/- 0.75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTUx_wbt4wpj",
        "colab_type": "text"
      },
      "source": [
        "So we currently perform ~10% better than a dummy classifier, awesome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25mXenkYTQ68",
        "colab_type": "text"
      },
      "source": [
        "# Other stuff (utilities)\n",
        "\n",
        "Some random stuff that was useful before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox29IUbZeWbV",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and uploading to GCP\n",
        "\n",
        "Following code blocks define code to download and upload training data to the GCP storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XocUcO2CejPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup GCP credentials\n",
        "project_id = 'positive-nuance-274811'\n",
        "bucket_name = 'recsys-twitter-challenge-us-jku-quarantwits'\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKMYJ3evtWsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download training data\n",
        "!gsutil cp gs://{bucket_name}/train_updated.tsv train_updated.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T6crXiJFwRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload partitioned training data to GCP\n",
        "\n",
        "# !gsutil cp train.001.tsv gs://{bucket_name}/train.001.tsv\n",
        "# !gsutil cp train.002.tsv gs://{bucket_name}/train.002.tsv\n",
        "# !gsutil cp train.003.tsv gs://{bucket_name}/train.003.tsv\n",
        "# !gsutil cp train.004.tsv gs://{bucket_name}/train.004.tsv\n",
        "# !gsutil cp train.005.tsv gs://{bucket_name}/train.005.tsv\n",
        "# !gsutil cp train.006.tsv gs://{bucket_name}/train.006.tsv\n",
        "\n",
        "# !gsutil cp train_updated.tsv gs://{bucket_name}/train_updated.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwd9x6q7e-Te",
        "colab_type": "text"
      },
      "source": [
        "## Download deleted tweet & user ID's\n",
        "\n",
        "Tweets & users can be removed over time and we have to remove the corresponding tweet engagements to adhere to GDPR. This piece of code downloads all these ID's so that they can be removed from our dataset in the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3BInNlNMmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -O tweetIDs_1.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/03/01'\n",
        "# !wget -O tweetIDs_2.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/03/08'\n",
        "# !wget -O tweetIDs_3.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/03/15'\n",
        "# !wget -O tweetIDs_4.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/03/22'\n",
        "# !wget -O tweetIDs_5.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/03/29'\n",
        "# !wget -O tweetIDs_6.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_engaged_with_tweet_id/2020/04/12'\n",
        "\n",
        "# !wget -O userIDs_1.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/03/01'\n",
        "# !wget -O userIDs_2.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/03/08'\n",
        "# !wget -O userIDs_3.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/03/15'\n",
        "# !wget -O userIDs_4.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/03/22'\n",
        "# !wget -O userIDs_5.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/03/29'\n",
        "# !wget -O userIDs_6.txt 'https://elasticbeanstalk-us-west-2-800068098556.s3-us-west-2.amazonaws.com/challenge-website/public_data/training/diffs/tsv_deleted_user_id/2020/04/12'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BlRacY7DG99",
        "colab_type": "text"
      },
      "source": [
        "## Removing removed user & tweet ID's\n",
        "\n",
        "After getting the removed ID's in the previous step this piece of code removes those ID's from the dataset and stores it as a new one. NOTE: this has to be run manually for each partition currently, by running it 6 times and changing the `00x` in the file names on lines `12` and `25` to the number of the partition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU9_NjK6d4iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
        "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
        "                \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\",\n",
        "                \"engaged_with_user_account_creation\", \"enaging_user_id\", \"enaging_user_follower_count\",\n",
        "                \"enaging_user_following_count\",\n",
        "                \"enaging_user_is_verified\", \"enaging_user_account_creation\", \"engagee_follows_engager\",\n",
        "                \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"]\n",
        "\n",
        "new_dataset = pd.read_csv('./train.006.tsv', delimiter=\"\\x01\", encoding='utf-8', header=None)\n",
        "new_dataset.columns = all_features\n",
        "\n",
        "# print(new_dataset.tweet_id)\n",
        "for i in range(1, 6):\n",
        "  removed_tweet_ids = pd.read_csv(\"tweetIDs_{}.txt\".format(i), header=None)\n",
        "  new_dataset = new_dataset[~new_dataset.tweet_id.isin(removed_tweet_ids[0])]\n",
        "\n",
        "for i in range(1, 6):\n",
        "  removed_user_ids = pd.read_csv(\"userIDs_{}.txt\".format(i), header=None)\n",
        "  new_dataset = new_dataset[~new_dataset.engaged_with_user_id.isin(removed_user_ids[0])]\n",
        "  new_dataset = new_dataset[~new_dataset.enaging_user_id.isin(removed_user_ids[0])]\n",
        "\n",
        "new_dataset.to_csv('./train_updated.006.tsv', sep=\"\\x01\", header=False, index=False, quoting=csv.QUOTE_NONE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSbeP12Jeyia",
        "colab_type": "text"
      },
      "source": [
        "## Unix tools used to split the dataset into partitions\n",
        "\n",
        "In order to have more manageable dataset pieces, they are partitioned into sets of 10GB so that they can be read into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0GAAJMmbj57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !chmod +x split.sh\n",
        "# !apt update && apt install -y bc\n",
        "# !./split.sh\n",
        "# !wc -l train.001.tsv\n",
        "cat train_updated.001.tsv train_updated.002.tsv train_updated.003.tsv train_updated.004.tsv train_updated.005.tsv train_updated.006.tsv > train_updated.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr22G4MmfjNs",
        "colab_type": "text"
      },
      "source": [
        "## Dataset sampler\n",
        "\n",
        "Can be used to create a random sample from a large training set. `sample_frequency` can be defined to what your heart desires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU8-NRQPfBaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_frequency = 1/6\n",
        "\n",
        "sampled_set = dataset.sample(frac=sample_frequency, random_state=4173141592)\n",
        "sampled_set.to_csv('./sample.tsv', sep=\"\\x01\", header=False, index=False, quoting=csv.QUOTE_NONE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzeUy0MlgXXA",
        "colab_type": "text"
      },
      "source": [
        "## Playground\n",
        "\n",
        "Playground based on the code snippet by the RecSys challenge itself.\n",
        "Can be used to efficiently read the first few lines of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P797Zmg22nbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_features = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
        "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
        "                \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\",\n",
        "                \"engaged_with_user_account_creation\", \"enaging_user_id\", \"enaging_user_follower_count\",\n",
        "                \"enaging_user_following_count\",\n",
        "                \"enaging_user_is_verified\", \"enaging_user_account_creation\", \"engagee_follows_engager\"]\n",
        "\n",
        "all_features_to_idx = dict(zip(all_features, range(len(all_features))))\n",
        "labels_to_idx = {\"reply_timestamp\": 20, \"retweet_timestamp\": 21, \"retweet_with_comment_timestamp\": 22,\n",
        "                 \"like_timestamp\": 23}\n",
        "\n",
        "\n",
        "def print_features(features):\n",
        "  print(len(features))\n",
        "  print(features)\n",
        "  print('-----------------')\n",
        "  for feature, idx in all_features_to_idx.items():\n",
        "        print(\"feature {} has value {}\".format(feature, features[idx]))\n",
        "\n",
        "  for label, idx in labels_to_idx.items():\n",
        "        print(\"label {} has value {}\".format(label, features[idx]))\n",
        "\n",
        "with open(train_file, encoding=\"utf-8\") as fileobject:\n",
        "    i = 0\n",
        "    for line in fileobject:\n",
        "        if i == 10:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        features = line.split(\"\\x01\")\n",
        "        i += 1\n",
        "        print_features(features)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RSN0ioo-Fr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sampled_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByJ3FVnoStcR",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing text_tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh77Lru5Itqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['text_tokens'] = dataset['text_tokens'].str.split(\"\\t\")\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYAmKWu1DasT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['text_tokens'] = dataset['text_tokens'].apply(lambda x: np.fromstring(x, dtype=int, sep=\"\\t\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}